{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 121\n",
      "CUDA SETUP: Loading binary /opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /opt/conda/envs/dev did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('[\"/tmp/vscode-ssh-auth-1d38f61d-f2d5-40a0-993a-97d7f1b36af9.sock\"]')}\n",
      "  warn(msg)\n",
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/bin')}\n",
      "  warn(msg)\n",
      "/opt/conda/envs/dev/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, set_peft_model_state_dict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"EleutherAI/pythia-2.8b\"\n",
    "#adapter_path = \"./models/adapter_pythia-2.8b_ep50_bs4.pth\"\n",
    "adapter_path = \"./models/adapter.pth\"\n",
    "max_memory = {0: \"22GIB\", \"cpu\": \"30GB\"}\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\") #, max_memory=max_memory)\n",
    "\n",
    "# small fix to get gpt generation working\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    inference_mode=True,\n",
    "    r=8, # better save and export the peft config used during training\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_weights = torch.load(adapter_path, map_location=\"cuda\")\n",
    "set_peft_model_state_dict(model, adapter_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")\n",
    "\n",
    "def predict(x, num_samples=1):\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            golden_sample = f\"Write a modern and engaging job posting for the following basic qualifications: {x}\\r\\nResponse: \\r\\n\"\n",
    "\n",
    "            inputs = tokenizer(golden_sample, return_tensors=\"pt\")\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
    "                do_sample=True,\n",
    "                temperature=0.9,\n",
    "                # num_beams=5,\n",
    "                max_length=1024,\n",
    "                num_return_sequences=num_samples,\n",
    "            )\n",
    "\n",
    "            responses = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)\n",
    "            \n",
    "            for response in responses:\n",
    "                print(os.linesep.join(response.split(\"\\r\\n\")))\n",
    "                print(\"-----------------------------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a modern and engaging job posting for the following basic qualifications: \n",
      "- You will work for StepStone and build revolutionary machine learning applications\n",
      "- You will redefine job search and job discovery experience for millions of users\n",
      "- You will bring Generative AI to the broad masses, greating great job experiences.\n",
      "\n",
      "Response: \n",
      "Job description\n",
      "- Are you seeking an opportunity to make a big impact on the future of search? We are looking for an experienced Sr. Software Engineering Engineer to join the Search & Discovery team, focused on delivering highly relevant and relevant job searches, improving the selection of applications that users get to interact with job assistance services and building out next- generation machine learning applications.\n",
      "- Are you seeking an opportunity to make a big impact on the future of job searching? Do you want to redefine how job seekers and recruiters find each other? We enable customers to find each other through a dynamic online job search platform. We are solving massive scale challenges to scale the organization and accelerate the job search experience on our platform. We are changing the way people search for jobs by expanding Amazon's job search capabilities in multiple verticals and improving the application of machine learning models to drive ad recommendations and rank the applicants on our job search platform. We are a rapidly growing organization in Seattle. We are growing by leaps and bounds and would like all of our organizations and engineering teams to grow and leverage their knowledge base and skills. As an engineer in our organization, you will be working with business and other technical teams to deliver scalable systems. You will work with the product team in Seattle. You will design, develop and deploy innovative, scalable solutions in the Search and Discovery and other areas. You will work with customers and partners to define and drive the future of this amazing business.\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "requirements = \"\"\"\n",
    "- You will work for StepStone and build revolutionary machine learning applications\n",
    "- You will redefine job search and job discovery experience for millions of users\n",
    "- You will bring Generative AI to the broad masses, greating great job experiences.\n",
    "\"\"\"\n",
    "\n",
    "requirements = \"\\r\\n\".join(requirements.split(os.linesep))\n",
    "predict(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a modern and engaging job posting for the following basic qualifications: \n",
      "- You want to be part of revolutionizing shoes\n",
      "- You are an expert in Shoe AI\n",
      "- You wear shoes all day long\n",
      "- You love shoes\n",
      "- You want to change the future with Amazon Shoes AI\n",
      "- You are an expert in smart business shoes powered by Amazon Alexa\n",
      "- You will work on the development of next generation smart shoes\n",
      "- Proven track record developing next generation shoe applications\n",
      "\n",
      "Response: \n",
      "We're looking for talented, focused, and hard working Software Engineers who have experience building innovative, mission critical, high volume application systems. If you're passionate about developing cutting edge technologies, and want to have a significant impact on customers, this role may be for you. Our team members have experience in artificial intelligence, machine learning, electronic engineering, and computing across the full stack. We are looking for team members that combine these areas to further the development of our systems. Your responsibilities will include all aspects of development, testing, deployment and operation of a system that is used by millions of Amazon. com customers. You will have direct customer interaction in your role as a software development engineer. You will be part of a strong team working closely with product managers, product managers and engineering leadership. Your experiences with technology, with this group or with other companies are a large source of your job description information. As an employee of Amazon you'll have the opportunity to work hard, have fun, and make history! Amazon is looking for diverse, passionate, talented and energetic individuals with experience of working on advanced machine learning systems. Ideal candidates will have industry experience in machine learning, data mining, or e- commerce applications. This is a chance to be part of a small and highly motivated team and help develop cutting edge technology that will serve millions of customers worldwide. Amazon is an Equal Opportunity- Affirmative Action Employer â€“ Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "requirements = \"\"\"\n",
    "- You want to be part of revolutionizing shoes\n",
    "- You are an expert in Shoe AI\n",
    "- You wear shoes all day long\n",
    "- You love shoes\n",
    "- You want to change the future with Amazon Shoes AI\n",
    "- You are an expert in smart business shoes powered by Amazon Alexa\n",
    "- You will work on the development of next generation smart shoes\n",
    "- Proven track record developing next generation shoe applications\n",
    "\"\"\"\n",
    "\n",
    "requirements = \"\\r\\n\".join(requirements.split(os.linesep))\n",
    "predict(requirements, num_samples=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
