{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from peft import LoraConfig, get_peft_model, set_peft_model_state_dict\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EleutherAI/pythia-2.8b\"\n",
    "#adapter_path = \"./models/adapter_pythia-2.8b_ep50_bs4.pth\"\n",
    "adapter_path = \"./models/adapter_pythia-2.8b_ep150_bs16.pth\"\n",
    "max_memory = {0: \"22GIB\", \"cpu\": \"30GB\"}\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\") #, max_memory=max_memory)\n",
    "\n",
    "# small fix to get gpt generation working\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if getattr(tokenizer, \"pad_token_id\") is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/dev/lib/python3.10/site-packages/peft/tuners/lora.py:173: UserWarning: fan_in_fan_out is set to True but the target module is not a Conv1D. Setting fan_in_fan_out to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    inference_mode=True,\n",
    "    r=8, # better save and export the peft config used during training\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_weights = torch.load(adapter_path, map_location=\"cuda\")\n",
    "model = set_peft_model_state_dict(model, adapter_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\")\n",
    "\n",
    "def predict(x, num_samples=1):\n",
    "    with torch.no_grad():\n",
    "        with torch.autocast(\"cuda\"):\n",
    "            golden_sample = f\"Write a modern and engaging job posting for the following basic qualifications: {x}\\r\\nResponse: \\r\\n\"\n",
    "\n",
    "            inputs = tokenizer(golden_sample, return_tensors=\"pt\")\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"].to(\"cuda\"),\n",
    "                do_sample=True,\n",
    "                temperature=0.9,\n",
    "                # num_beams=5,\n",
    "                max_length=1024,\n",
    "                num_return_sequences=num_samples,\n",
    "            )\n",
    "\n",
    "            responses = tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)\n",
    "            \n",
    "            for response in responses:\n",
    "                print(os.linesep.join(response.split(\"\\r\\n\")))\n",
    "                print(\"-----------------------------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a modern and engaging job posting for the following basic qualifications: \n",
      "- You will be part of Stepstone Emerging Technologies team\n",
      "- You will redefine job search and job discovery experience for millions of users\n",
      "- You will build MVPs and prototypes to test new ideas and technologies\n",
      "\n",
      "Response: \n",
      "The ideal candidate will be excited and passionate about the opportunities and challenge of building innovative new products that help people find each other. Do you have vision and passion for how people find each other? Do you think about how to improve the user experience when browsing through millions of users? If yes, we want to talk to you. If you are inspired by the unlimited potential of the cloud, and the profound impact that new technology and architectures have on the way consumers use computers, we would like to talk to you. If you want to make disruptive improvements that dramatically change the way people work, we'd like to talk to you. If you are excited about architecting large- scale systems, we’d like to talk to you. If you are interested in solving big problems at scale, we’d like to talk to you. If you are a proven product manager who is passionate about designing software that customers love, we’d love to talk to you. Everyday tasks include:\n",
      "- designing and coding software that enables large scale user experience improvements\n",
      "- leading and organizing design sessions with designers\n",
      "- building prototypes and MVP's to validate new ideas\n",
      "- inventing new features for Enterprise- ready software\n",
      "- helping accelerate projects through engineering and collaborative expertise\n",
      "- communicating with OO customers to understand their needs and establish product features\n",
      "- participating in defining feature rollout strategies\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "requirements = \"\"\"\n",
    "- You will be part of Stepstone Emerging Technologies team\n",
    "- You will redefine job search and job discovery experience for millions of users\n",
    "- You will build MVPs and prototypes to test new ideas and technologies\n",
    "\"\"\"\n",
    "\n",
    "requirements = \"\\r\\n\".join(requirements.split(os.linesep))\n",
    "predict(requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a modern and engaging job posting for the following basic qualifications: \n",
      "- You want to be part of revolutionizing shoes\n",
      "- You are an expert in Shoe AI\n",
      "- You wear shoes all day long\n",
      "- You love shoes\n",
      "- You want to change the future with Amazon Shoes AI\n",
      "- You are an expert in smart business shoes powered by Amazon Alexa\n",
      "- You will work on the development of next generation smart shoes\n",
      "- Proven track record developing next generation shoe applications\n",
      "\n",
      "Response: \n",
      "All right, let's talk about the shoes. (Yes, that's plural. There are many pairs of shoes. And we're talking about shoes. Not clothes, nor books, not hardware nor software platforms. The shoes are on feet. Why would we talk about shoes? Because shoes are so important! When you step into a room, your shoes make a very loud squishing noise. They create a ton of friction and pressure as you walk. And when your shoes are broken or dirty, they make a very noticeable squeaking sound. Your shoes define you. And you can change that. We are at the beginning of a revolution in footwear design and development. We've got big plans, and we want you to be part of it. We aim to transform the way people shop and interact with shoes. We are looking for passionate, independent software engineers who want to have an enormous impact on footwear and the way we use technology to improve our lives. You'll work on cutting edge voice- and touch- enabled shoes. You'll collaborate with scientists, researchers, and researchers at industry leading shops, helping to develop the next generation of shoe- friendly technologies. You'll work on new user interfaces, designing ways to make shoes smart and make shopping easy. You'll work with business and technology leaders to implement these applications. You'll make history by helping to change the way people shop and interact with shoes. If you want to join a team that's inventing the future of shoes, think about this job!\n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "requirements = \"\"\"\n",
    "- You want to be part of revolutionizing shoes\n",
    "- You are an expert in Shoe AI\n",
    "- You wear shoes all day long\n",
    "- You love shoes\n",
    "- You want to change the future with Amazon Shoes AI\n",
    "- You are an expert in smart business shoes powered by Amazon Alexa\n",
    "- You will work on the development of next generation smart shoes\n",
    "- Proven track record developing next generation shoe applications\n",
    "\"\"\"\n",
    "\n",
    "requirements = \"\\r\\n\".join(requirements.split(os.linesep))\n",
    "predict(requirements, num_samples=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
